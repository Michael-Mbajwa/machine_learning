{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from efficient_apriori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "plants = pd.read_table(\"data/plants.data\", encoding='latin-1', names=['col'])\n",
    "states = pd.read_csv(\"data/stateabbr.txt\", encoding='latin-1',skiprows=[0, 2, 58], names=['States'])\n",
    "all_states = states['States'].str.split(' ').apply(pd.Series).iloc[:, 0].to_numpy()  # Might not be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{fl, ms} -> {al} (conf: 0.955, supp: 0.103, lift: 5.825, conv: 18.536)\n"
     ]
    }
   ],
   "source": [
    "# I do a bit of simple data cleaning to get it ready as transactions\n",
    "temp = plants['col'].str.split(',').to_numpy()\n",
    "transactions = []\n",
    "for i in range(len(temp)):\n",
    "  lst = tuple(temp[i][1:])\n",
    "  transactions.append(lst)\n",
    "\n",
    "# Using the apriori algorithm, we specify values for min_support and minimum_confidence\n",
    "itemsets, rules = apriori(transactions=transactions, min_support=0.1, min_confidence=0.95)\n",
    "print(rules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more complicated data cleaning for further machine learning tasks\n",
    "df = plants['col'].str.split(',').apply(pd.Series)  # plant specie and state codes are separated by comma\n",
    "df.rename(columns={0: 'specie'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.melt(df, ['specie'])  # to prepare the data for one hot encoding, we first transform it to a long format\n",
    "df_temp.drop(columns=['variable'], inplace=True)  # drop the variable column created from column names\n",
    "df_temp.rename(columns={'value': 'state'}, inplace=True)  # rename column called value to state\n",
    "df_temp.dropna(inplace=True)  # remove NA values at this stage\n",
    "df_temp.reset_index(inplace=True)  # Index is messed up as a result of dropna so we reset it\n",
    "df_temp.drop('index', axis=1, inplace=True)  # duplicated index column created from reset_index. It is deleted.\n",
    "specie = df_temp['specie']  # Store all names of specie based on the order of appearance to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df_temp.state)  # step 1 of creating one hot encoding\n",
    "\n",
    "# Since we melted the dataset previously and transformed it to a long format, it meant that df_ohe contains one hot encoding for one specie and one \n",
    "# location. The correct form is one specie and all locations.\n",
    "\n",
    "# To correct this, we will add the specie column we previously extracted to df_ohe\n",
    "df_ohe['specie'] = specie\n",
    "\n",
    "# Groupy the the dataset by species and combine (add) the differe one hot encodings together to give the final resuly\n",
    "def add_ohe(df):\n",
    "    combined = df.sum(axis=0)\n",
    "    return combined\n",
    "\n",
    "df_ohe = df_ohe.groupby('specie').apply(add_ohe)\n",
    "df_ohe.drop('specie', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_ohe.index.to_numpy()  # create labels\n",
    "features = df_ohe.to_numpy()  # create features"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
