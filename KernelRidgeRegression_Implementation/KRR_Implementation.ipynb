{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRR():\n",
    "    def __init__(self, alpha=1.0, gamma=1.0, degree=2, coef0=1, kernel='rbf'):\n",
    "        self.alpha = alpha  # Ridge parameter.\n",
    "        self.gamma = gamma  # Gamma parameter for the RBF and polynomial kernels.\n",
    "        self.degree = degree  # Degree of the polynomial kernel. Ignored by other kernels.\n",
    "        self.coef0 = coef0  # Zero coefficient for polynomial and sigmoid kernel. Ignored by other kernels.\n",
    "        self.kernel = kernel  # Kernel mapping.\n",
    "        self.weights = None\n",
    "        self.x_train = None\n",
    "    \n",
    "    # I will first define all the kernel functions.\n",
    "    # For many real problems, the underlying model cannot be described\n",
    "    # by a linear function, so linear ridge regression suffers from poor\n",
    "    # prediction error. In those cases, a common approach is to map\n",
    "    # samples to a high dimensional space using a nonlinear mapping,\n",
    "    # and then learn the model in the high dimensional space. Kernel\n",
    "    # method is a widely used approach to conduct this learning\n",
    "    # procedure implicitly by defining the kernel function — the similarity\n",
    "    # of samples in the high dimensional space.\n",
    "    # https://scikit-learn.org/stable/modules/metrics.html#metrics\n",
    "    \n",
    "    def linear(self, x1, x2):\n",
    "        \"\"\"\n",
    "        A linear kernel function with the formula: Φ(x1, x2) = x1*x2\n",
    "        \"\"\"\n",
    "        linear_kernel = np.dot(x1.T, x2)\n",
    "        return linear_kernel\n",
    "    \n",
    "    def polynomial(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Polynomial kernel function with formula: Φ(x1, x2) = (r + x1 · x2)d, for some r ≥ 0, d > 0\n",
    "        \"\"\"\n",
    "        d = self.degree\n",
    "        r = self.coef0\n",
    "        a = self.gamma\n",
    "        poly_kernel = np.power(r + np.dot(a*x1.T, x2), d)\n",
    "        return poly_kernel\n",
    "    \n",
    "    def rbf(self, x1, x2):\n",
    "        \"\"\"\n",
    "        The radial basis kernel function with formula: Φ(x1, x2) = exp(-a||x1 - x2||2), gamma > 0\n",
    "        \"\"\"\n",
    "        y = self.gamma\n",
    "        y = y * -1\n",
    "        rbf_kernel = np.exp(y * np.sum(np.square((x1-x2))))\n",
    "        return rbf_kernel\n",
    "\n",
    "    def sigmoid(self, x1, x2):\n",
    "        \"\"\"\n",
    "        The sigmoid kernel function with formula: Φ(x1, x2) = tanh(ax1 * x2 + r )\n",
    "        \"\"\"\n",
    "        a = self.gamma\n",
    "        r = self.coef0\n",
    "        sigmoid_kernel = np.tanh(np.dot(a * x1.T, x2) + r)\n",
    "        return sigmoid_kernel\n",
    "    \n",
    "    def kernel_matrix(self, x):\n",
    "        \"\"\"\n",
    "        Create an n*n kernel matrix K using the user-specified kernel function.\n",
    "\n",
    "        # Use this code to replace the nested loop\n",
    "        x1, x2 = np.meshgrid(x_train)\n",
    "        k_mat = kernel_functions[self.kernel](x1, x2)\n",
    "        \"\"\"\n",
    "        # Initialize hash table for kernel functions.\n",
    "        kernel_functions = {'linear': self.linear, 'rbf': self.rbf, 'poly': self.polynomial, \n",
    "                            'sigmoid': self.sigmoid}\n",
    "        \n",
    "        # Create an empty array for the matrix. More efficient since we avoid growing our vector.\n",
    "        k_mat = np.empty((x.shape[0], x.shape[0]), dtype=float)\n",
    "\n",
    "        # Calculate values for the matrix using the kernel function specified by the user\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[0]):\n",
    "                km = kernel_functions[self.kernel](x[i], x[j])\n",
    "                k_mat[i][j] = km\n",
    "        \n",
    "        return k_mat\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        In the Training phase, the algorithm's goal is to get α by (approximately) solving the linear system;\n",
    "        (K + λnI)α = y\n",
    "        α = inverse(K + λnI) * y\n",
    "        \"\"\"\n",
    "        self.x_train = x\n",
    "        n = x.shape[0]\n",
    "        # alpha_param λnI\n",
    "        alpha_param = self.alpha*np.identity(n, dtype=float)\n",
    "        \n",
    "        # Construct your kernel matrix\n",
    "        k_matrix = self.kernel_matrix(x)\n",
    "        \n",
    "        # solve for α = inverse(K + λnI) * y\n",
    "        self.weights = np.dot(np.linalg.inv(np.add(k_matrix, alpha_param)), y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        yj = sum(αi*K(xi, xj) where i = 1,...,n\n",
    "        \"\"\"\n",
    "        kernel_functions = {'linear': self.linear, 'rbf': self.rbf, 'poly': self.polynomial, \n",
    "                            'sigmoid': self.sigmoid}\n",
    "\n",
    "        if self.weights is None:\n",
    "            return \"Model not yet trained.\"\n",
    "\n",
    "        # Create an empty array for the predicted values to avoid a growing vector/array\n",
    "        y_pred = np.empty((x.shape[0]), dtype=float)\n",
    "        # Calculate predicted values\n",
    "        for j in range(x.shape[0]):\n",
    "            y_pred[j] = np.sum([np.dot(self.weights[i], kernel_functions[self.kernel](self.x_train[i], x[j])) for i in range(0, self.x_train.shape[0])])\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        rmse_score = np.sqrt(np.mean(np.square((y_pred - y))))\n",
    "        return rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchCV():\n",
    "    def __init__(self, param_grid, n_splits=5, shuffle=True):\n",
    "        # Because of time constraint, I only used rmse scoring\n",
    "        \n",
    "        self.param_grid = param_grid  # A dictionary\n",
    "        self.n_splits = n_splits  # Number of folds. Must be atleast 2. Default is 5.\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def grid_parameters(self):\n",
    "        \"\"\"\n",
    "        For constructing a grid of the parameters provided by the user\n",
    "        param_grid={\"alpha\": alpha, \"gamma\": gamma\n",
    "        For example: grid_parameters({\"alpha\": [1, 2, 3], \"gamma\": [4, 5]}) would return: \n",
    "        [{'alpha': 1, 'gamma': 4},\n",
    "        {'alpha': 1, 'gamma': 5},\n",
    "        {'alpha': 2, 'gamma': 4},\n",
    "        {'alpha': 2, 'gamma': 5},\n",
    "        {'alpha': 3, 'gamma': 4},\n",
    "        {'alpha': 3, 'gamma': 5}]\n",
    "        https://github.com/scikit-learn/scikit-learn/blob/37ac6788c9504ee409b75e5e24ff7d86c90c2ffb/sklearn/model_selection/_search.py#L50\n",
    "        \"\"\"\n",
    "        grid = []\n",
    "        items = sorted(self.param_grid.items())  # sort keys of dictionary for reproducibility\n",
    "        keys, values = zip(*items)\n",
    "        for v in product(*values):\n",
    "            params = dict(zip(keys, v))\n",
    "            grid.append(params)\n",
    "        return grid\n",
    "    \n",
    "    def train(self, x, y):\n",
    "        \"\"\"\n",
    "        This method runs fit with all sets of parameters\n",
    "        param x: the arrays representing the features\n",
    "        param y: the arrays representing the labels\n",
    "        \"\"\"\n",
    "        x_folds = np.array_split(x, self.n_splits)\n",
    "        y_folds = np.array_split(y, self.n_splits)\n",
    "        scores = {'alpha':[], 'gamma': [], 'rmse': []}\n",
    "        grids = self.grid_parameters()\n",
    "        i = 0\n",
    "\n",
    "        print(\"Fitting 5 folds for each {} candidates.\". format(len(grids)))\n",
    "        for grid in grids:\n",
    "            for k in range(self.n_splits):\n",
    "                # Split the data\n",
    "                x_train = list(x_folds)\n",
    "                x_test = x_train.pop(k)\n",
    "                x_train = np.concatenate(x_train)\n",
    "\n",
    "                y_train = list(y_folds)\n",
    "                y_test = y_train.pop(k)\n",
    "                y_train = np.concatenate(y_train)\n",
    "\n",
    "                model = KRR(alpha=grid['alpha'], gamma=grid['gamma'])\n",
    "                model.fit(x_train, y_train)\n",
    "                score = model.score(x_test, y_test)\n",
    "\n",
    "                scores['alpha'].append(grid['alpha'])\n",
    "                scores['gamma'].append(grid['gamma'])\n",
    "                scores['rmse'].append(score)\n",
    "            i +=1\n",
    "        \n",
    "        print(\"Finished fitting 5 folds for each {} candidates.\". format(len(grids)))\n",
    "        scores_df = pd.DataFrame(scores)\n",
    "        best_scores = scores_df[scores_df['rmse'] == scores_df['rmse'].min()]\n",
    "        \n",
    "        \n",
    "        # finally fit the model with the best parameters\n",
    "        best_alpha = best_scores['alpha'].values[0]\n",
    "        best_gamma = best_scores['gamma'].values[0]\n",
    "        best_score = best_scores['rmse'].values[0]\n",
    "\n",
    "        KRR(alpha=best_alpha, gamma=best_gamma).fit(x, y)\n",
    "        print('Fitted.')\n",
    "    \n",
    "        return best_alpha, best_gamma, best_score\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        predict y for x using the best parameters.\n",
    "        \"\"\"\n",
    "        y_pred = KRR().predict(x)\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def best_paramaters(self):\n",
    "        \"\"\"\n",
    "        Returns best output\n",
    "        \"\"\"\n",
    "        best_alpha = self.best_params.alpha\n",
    "        best_gamma = self.best_params.gamma\n",
    "        output = 'Best: alpha = {}, gamma = {}'.format(best_alpha, best_gamma)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22140, 1) (22140, 15, 3)\n",
      "(22140, 105)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data = np.load('toluene.npz')\n",
    "   \n",
    "E = data['E'] \n",
    "R = data['R']\n",
    "\n",
    "E -= E.min()\n",
    "D = np.array([1./pdist(r) for r in R])\n",
    "print(E.shape, R.shape)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, E, train_size=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each 12 candidates.\n",
      "Finished fitting 5 folds for each 12 candidates.\n",
      "Fitted.\n"
     ]
    }
   ],
   "source": [
    "krr = GridSearchCV(param_grid={\"alpha\": np.logspace(-12, -6, 3), \"gamma\": np.array([1e-12, 0.004, 1e-6, 0.04])})\n",
    "best_alpha, best_gamma, best_score = krr.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.319678411060403"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr_model = KRR(alpha=best_alpha, gamma=best_gamma)\n",
    "krr_model.fit(X_train, y_train)\n",
    "y_train_predicted = krr_model.predict(X_train)\n",
    "y_test_predicted = krr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = lambda X, Y: np.mean(np.absolute((X - Y)))\n",
    "rmse = lambda X, Y: np.sqrt(np.mean(np.square((X - Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: MAE = 3.943 kcal/mol, RMSE = 4.933 kcal/mol\n",
      "Tset: MAE = 4.074 kcal/mol, RMSE = 5.112 kcal/mol\n"
     ]
    }
   ],
   "source": [
    "train_mae = mae(y_train_predicted, y_train)\n",
    "train_rmse = rmse(y_train_predicted, y_train)\n",
    "test_mae = mae(y_test_predicted, y_test)\n",
    "test_rmse = rmse(y_test_predicted, y_test)\n",
    "\n",
    "print('Train: MAE = {:.3f} kcal/mol, RMSE = {:.3f} kcal/mol'. format(train_mae, train_rmse))\n",
    "print('Tset: MAE = {:.3f} kcal/mol, RMSE = {:.3f} kcal/mol'. format(test_mae, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    " \n",
    "plt.scatter(y_train, y_train_predicted, marker='.', color='green', zorder=2)\n",
    "plt.scatter(y_test, y_test_predicted, marker='.', color='blue', zorder=1)\n",
    "plt.title('MAE = {:.3f} kcal/mol, RMSE = {:.3f} kcal/mol'.format(test_mae, test_rmse))\n",
    "#plt.savefig('krr.png', dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
